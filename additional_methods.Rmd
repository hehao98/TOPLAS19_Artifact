---
title: "Additional Methods: Panel Analysis with Fixed Effects"
output: html_document
---

This notebook implements panel analyses at the repository and developer levels with fixed effects.

# Setup

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(MASS)
library(lmtest)
library(sandwich)
library(knitr)
library(kableExtra)
library(fixest)

WORKING_DIR = "./artifact/re-analysis"
```

# Helper Functions

```{r, helper_functions}
# Extract coefficients from model (glm.nb or fixest, zero-sum contrasts)
extractCoefs = function(model, Y) {
    all_langs = levels(Y$language)
    n_langs = length(all_langs)
    
    ctrl_names = c("(Intercept)"="Intercept", "lmax_commit_age"="log(age)",
                   "ltins"="log(size)", "ldevs"="log(devs)", "lcommits"="log(commits)",
                   "lprojects"="log(projects)")
    lang_order = c("C","C++","C#","Objective-C","Go","Java","Coffeescript",
                   "Javascript","Ruby","Php","Python","Perl","Clojure","Erlang","Haskell","Scala")
    
    # Get coefficient table
    if (inherits(model, "fixest")) {
        ct = as.data.frame(coeftable(model))
    } else {
        ct = as.data.frame(summary(model)$coefficients)
    }
    ct$name = rownames(ct)
    
    # Extract controls
    ctrl = ct[ct$name %in% names(ctrl_names), ]
    ctrl_labels = ctrl_names[ctrl$name]
    
    # Extract language rows (numbered for zero-sum: language1, language2, ...)
    lang_rows = grep("^language", ct$name)
    lang_ct = ct[lang_rows, ]
    
    # Zero-sum: map language1..N-1 to actual names, compute reference
    modeled_langs = all_langs[1:(n_langs - 1)]
    ref_lang = all_langs[n_langs]
    ref_coef = -sum(lang_ct[,1])
    ref_se = tryCatch(sqrt(sum(vcov(model)[lang_rows, lang_rows])), error = function(e) NA)
    ref_pval = if(!is.na(ref_se)) 2*pnorm(-abs(ref_coef/ref_se)) else NA
    
    # Combine language coefficients
    lang_coefs = setNames(c(lang_ct[,1], ref_coef), c(modeled_langs, ref_lang))
    lang_ses = setNames(c(lang_ct[,2], ref_se), c(modeled_langs, ref_lang))
    lang_pvals = setNames(c(lang_ct[,4], ref_pval), c(modeled_langs, ref_lang))
    
    # Reorder and combine
    lang_order = lang_order[lang_order %in% names(lang_coefs)]
    
    data.frame(
        Variable = c(ctrl_labels, lang_order),
        coef = round(c(ctrl[,1], lang_coefs[lang_order]), 3),
        se = round(c(ctrl[,2], lang_ses[lang_order]), 3),
        pVal = c(ctrl[,4], lang_pvals[lang_order]),
        row.names = NULL
    )
}

# Adjust p-values (FDR and Bonferroni)
adjustPValues = function(result) {
    result$pVal_fdr = round(p.adjust(result$pVal, "fdr"), 3)
    result$pVal_bonf = round(p.adjust(result$pVal, "bonferroni"), 3)
    result
}

# Convert p-value to significance marker (using HTML entities to avoid markdown interpretation)
sigMarker = function(p) {
    ifelse(is.na(p), "",
           ifelse(p < 0.001, "&#42;&#42;&#42;",
                  ifelse(p < 0.01, "&#42;&#42;",
                         ifelse(p < 0.05, "&#42;", ""))))
}

# Generate HTML table with significance markers and model stats
generateHTMLTable = function(df, title, model, data) {
    tbl = data.frame(
        Variable = df$Variable,
        Coef = sprintf("%.3f", df$coef),
        SE = sprintf("%.3f", df$se),
        Raw = sigMarker(df$pVal),
        FDR = sigMarker(df$pVal_fdr),
        Bonf = sigMarker(df$pVal_bonf)
    )
    
    # Get model statistics from actual model fitting
    if (inherits(model, "fixest")) {
        n_obs = nobs(model)
        fe_list = fixef(model)
        fe_names = names(fe_list)
        n_repos = if("project" %in% fe_names) length(fe_list$project) else 
                  if("project" %in% names(data)) length(unique(data$project)) else NA
        n_devs = if("author" %in% fe_names) length(fe_list$author) else 
                 if("author" %in% names(data)) length(unique(data$author)) else NA
        r2_all = tryCatch(fixest::r2(model), error = function(e) NULL)
        pr2 = if(!is.null(r2_all) && "pr2" %in% names(r2_all) && !is.na(r2_all["pr2"])) r2_all["pr2"] else NA
        # Try wr2 first (linear), then wpr2 (within pseudo-R² for non-linear)
        wr2 = if(!is.null(r2_all) && "wr2" %in% names(r2_all) && !is.na(r2_all["wr2"])) r2_all["wr2"] else 
              if(!is.null(r2_all) && "wpr2" %in% names(r2_all) && !is.na(r2_all["wpr2"])) r2_all["wpr2"] else NA
    } else {
        n_obs = nobs(model)
        n_repos = if("project" %in% names(data)) length(unique(data$project)) else NA
        n_devs = if("author" %in% names(data)) length(unique(data$author)) else NA
        pr2 = 1 - model$deviance/model$null.deviance
        wr2 = NA
    }
    
    # Build stats string
    stats = sprintf("N=%d", n_obs)
    if (!is.na(n_repos)) stats = paste0(stats, sprintf(" | Repos=%d", n_repos))
    if (!is.na(n_devs)) stats = paste0(stats, sprintf(" | Devs=%d", n_devs))
    if (!is.na(pr2) && length(pr2) == 1) stats = paste0(stats, sprintf(" | Pseudo-R²=%.3f", pr2))
    if (!is.na(wr2) && length(wr2) == 1) stats = paste0(stats, sprintf(" | Within-R²=%.3f", wr2))
    
    kable(tbl, format = "html", escape = FALSE, caption = title, align = c("l", "r", "r", "c", "c", "c")) %>%
        kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE) %>%
        footnote(general = c(stats, "Significance: * p<0.05, ** p<0.01, *** p<0.001"))
}
```

# Load Data

```{r, load_data_panel_1}
data = read.csv(paste0(WORKING_DIR, "/Data/commits.csv"))
cat(sprintf("Loaded %d commits | %d languages | %d repositories | %d developers\n",
    nrow(data), length(unique(data$language)), length(unique(data$project)), length(unique(data$author))))
```

# Panel 1: Repository-Language Level

Each observation is a unique (repository, language) pair.

## Data Preparation

```{r, data_preparation_panel_1}
panel_repo = data %>%
    group_by(project, language) %>%
    summarize(
        commits = n(),
        bcommits = sum(isbug),
        tins = sum(insertion),
        max_commit_age = max(commit_age),
        devs = n_distinct(author),
        .groups = "drop"
    ) %>%
    mutate(
        language = factor(language),
        project = factor(project),
        lcommits = log(commits),
        ltins = log(tins),
        lmax_commit_age = log(max_commit_age),
        ldevs = log(devs)
    )

contrasts(panel_repo$language) = contr.sum(nlevels(panel_repo$language))

cat(sprintf("Repository-Language panel: %d observations | %d repositories | %d languages\n",
    nrow(panel_repo), length(unique(panel_repo$project)), length(unique(panel_repo$language))))
```

## NBR with Zero-Sum Contrasts (Replicating Berger et al. 2019)

```{r, nbr_repo_panel_1}
nbr_repo = glm.nb(
    bcommits ~ lmax_commit_age + ltins + ldevs + lcommits + language,
    contrasts = list(language = contr.sum),
    data = panel_repo
)

result_repo = extractCoefs(nbr_repo, panel_repo)
result_repo = adjustPValues(result_repo)
generateHTMLTable(result_repo, "Model 1: Repository-Language Panel, Berger et al. 2019", nbr_repo, panel_repo)
```

## NBR with Repository Fixed Effects

```{r, nbr_repo_fe_panel_1}
nbr_repo_fe = fenegbin(
    bcommits ~ lmax_commit_age + ltins + ldevs + lcommits + language | project,
    data = panel_repo,
    vcov = ~project  # HC robust SE clustered at repository level
)

result_repo_fe = extractCoefs(nbr_repo_fe, panel_repo)
result_repo_fe = adjustPValues(result_repo_fe)
generateHTMLTable(result_repo_fe, "Model 2: Repository-Language Panel, Repository Fixed Effects", nbr_repo_fe, panel_repo)
```

# Panel 2: Developer-Language Level

Each observation is a unique (developer, language) pair.

## Data Preparation

```{r, data_preparation_panel_2}
panel_dev = data %>%
    group_by(author, language) %>%
    summarize(
        commits = n(),
        bcommits = sum(isbug),
        tins = sum(insertion),
        max_commit_age = max(commit_age),
        projects = n_distinct(project),
        .groups = "drop"
    ) %>%
    mutate(
        language = factor(language),
        author = factor(author),
        lcommits = log(commits),
        ltins = log(tins),
        lmax_commit_age = log(max_commit_age),
        lprojects = log(projects)
    )

# Set zero-sum contrasts for language (deviation from grand mean)
contrasts(panel_dev$language) = contr.sum(nlevels(panel_dev$language))

cat(sprintf("Developer-Language panel: %d observations | %d developers | %d languages\n",
    nrow(panel_dev), length(unique(panel_dev$author)), length(unique(panel_dev$language))))
```

## Poisson with Developer Fixed Effects

Using Poisson instead of Negative Binomial because with many fixed effects, overdispersion is absorbed and theta becomes very high.


```{r, nbr_dev_fe_panel_2}
nbr_dev_fe = fepois(
    bcommits ~ lmax_commit_age + ltins + lprojects + lcommits + language | author,
    data = panel_dev,
    vcov = ~author  # HC robust SE clustered at developer level
)

result_dev_fe = extractCoefs(nbr_dev_fe, panel_dev)
result_dev_fe = adjustPValues(result_dev_fe)
generateHTMLTable(result_dev_fe, "Model 3: Developer-Language Panel, With Developer Fixed Effects", nbr_dev_fe, panel_dev)
```

# Panel 3: Developer-Repository-Language Level

Each observation is a unique (developer, repository, language) tuple.

## Data Preparation

```{r, data_preparation_panel_3}
panel_dev_repo = data %>%
    group_by(author, project, language) %>%
    summarize(
        commits = n(),
        bcommits = sum(isbug),
        tins = sum(insertion),
        max_commit_age = max(commit_age),
        .groups = "drop"
    ) %>%
    mutate(
        language = factor(language),
        author = factor(author),
        project = factor(project),
        lcommits = log(commits),
        ltins = log(tins),
        lmax_commit_age = log(max_commit_age)
    )

# Set zero-sum contrasts for language (deviation from grand mean)
contrasts(panel_dev_repo$language) = contr.sum(nlevels(panel_dev_repo$language))

cat(sprintf("Developer-Repository-Language panel: %d observations | %d developers | %d repositories | %d languages\n",
    nrow(panel_dev_repo), length(unique(panel_dev_repo$author)), 
    length(unique(panel_dev_repo$project)), length(unique(panel_dev_repo$language))))
```

## Poisson with Developer + Repository Fixed Effects (Two-way FE)

```{r, pois_dev_repo_twoway_fe_panel_3}
pois_dev_repo_twoway_fe = fepois(
    bcommits ~ lmax_commit_age + ltins + lcommits + language | author + project,
    data = panel_dev_repo,
    vcov = ~author + project  # Two-way clustered SE
)

result_twoway_fe = extractCoefs(pois_dev_repo_twoway_fe, panel_dev_repo)
result_twoway_fe = adjustPValues(result_twoway_fe)
generateHTMLTable(result_twoway_fe, "Model 4: Developer-Repository-Language Panel, Two-Way Fixed Effects", pois_dev_repo_twoway_fe, panel_dev_repo)
```

# Summary Table: All Models

```{r, summary_table}
# Ray et al. 2014 (FSE) baseline results - language coefficients only
baselineRay2014 = function() {
    lang_names = c("C", "C++", "C#", "Objective-C", "Go", "Java", "Coffeescript", 
                   "Javascript", "Typescript", "Ruby", "Php", "Python", "Perl", 
                   "Clojure", "Erlang", "Haskell", "Scala")
    coefs = c(0.15, 0.23, 0.03, 0.18, -0.08, -0.01, -0.07, 0.06, -0.43, -0.15, 
              0.15, 0.10, -0.15, -0.29, -0.0, -0.23, -0.28)
    ses = c(.04, .04, .05, .05, .06, .04, .05, .02, .06, .04, .05, .03, .08, .05, .05, .06, .05)
    pvals = c(0.001, 0.001, NA, 0.001, NA, NA, NA, 0.01, 0.001, 0.05, 0.001, 0.01, NA, 0.001, NA, 0.001, 0.001)
    data.frame(Variable = lang_names, coef = coefs, se = ses, pVal = pvals, stringsAsFactors = FALSE)
}

# Function to create a summary table for all models (languages only)
createSummaryTable = function(results_list, model_names, models_list, data_list, include_baseline = TRUE) {
    # Only include language variables (no controls)
    lang_order = c("C", "C++", "C#", "Objective-C", "Go", "Java", "Coffeescript",
                   "Javascript", "Ruby", "Php", "Python", "Perl", "Clojure", "Erlang", "Haskell", "Scala")
    all_vars = lang_order[lang_order %in% unique(unlist(lapply(results_list, function(r) r$Variable)))]
    
    # Build summary data frame
    summary_df = data.frame(Variable = all_vars, stringsAsFactors = FALSE)
    
    # Add Ray et al. 2014 baseline as first column
    if (include_baseline) {
        baseline = baselineRay2014()
        coef_col = c()
        se_col = c()
        for (v in all_vars) {
            idx = which(baseline$Variable == v)
            if (length(idx) == 1) {
                sig = sigMarker(baseline$pVal[idx])
                coef_col = c(coef_col, paste0(sprintf("%.2f", baseline$coef[idx]), sig))
                se_col = c(se_col, sprintf("(%.2f)", baseline$se[idx]))
            } else {
                coef_col = c(coef_col, "NA")
                se_col = c(se_col, "")
            }
        }
        summary_df$Coef_0 = coef_col
        summary_df$SE_0 = se_col
    }
    
    for (i in seq_along(results_list)) {
        res = results_list[[i]]
        coef_col = c()
        se_col = c()
        
        for (v in all_vars) {
            idx = which(res$Variable == v)
            if (length(idx) == 1) {
                sig = sigMarker(res$pVal_fdr[idx])
                coef_col = c(coef_col, paste0(sprintf("%.3f", res$coef[idx]), sig))
                se_col = c(se_col, sprintf("(%.3f)", res$se[idx]))
            } else {
                coef_col = c(coef_col, "")
                se_col = c(se_col, "")
            }
        }
        
        summary_df[[paste0("Coef_", i)]] = coef_col
        summary_df[[paste0("SE_", i)]] = se_col
    }
    
    # Interleave columns
    col_order = c("Variable")
    if (include_baseline) col_order = c(col_order, "Coef_0", "SE_0")
    for (i in seq_along(results_list)) {
        col_order = c(col_order, paste0("Coef_", i), paste0("SE_", i))
    }
    summary_df = summary_df[, col_order]
    
    # Build model statistics rows
    stats_rows = data.frame(
        Variable = c("", "Observations", "Repositories", "Developers", "Fixed Effects", "Pseudo-R²", "Within-Pseudo-R²"),
        stringsAsFactors = FALSE
    )
    
    # Add baseline stats (Ray et al. 2014: 728 projects aggregated)
    if (include_baseline) {
        stats_rows$Coef_0 = c("", "728", "728", "NA", "None", "NA", "NA")
        stats_rows$SE_0 = c("", "", "", "", "", "", "")
    }
    
    for (i in seq_along(models_list)) {
        m = models_list[[i]]
        d = data_list[[i]]
        
        # Get actual observations used in model fitting
        if (inherits(m, "fixest")) {
            n_obs = nobs(m)
            fe_list = fixef(m)
            fe_names = names(fe_list)
            fe = paste(fe_names, collapse = " + ")
            if (fe == "") fe = "None"
            
            # Get actual number of FE groups used
            n_repos = if("project" %in% fe_names) length(fe_list$project) else NA
            n_devs = if("author" %in% fe_names) length(fe_list$author) else NA
            
            r2_all = tryCatch(fixest::r2(m), error = function(e) NULL)
            pr2 = if(!is.null(r2_all) && "pr2" %in% names(r2_all) && !is.na(r2_all["pr2"])) r2_all["pr2"] else NA
            # Try wr2 first (linear), then wpr2 (within pseudo-R² for non-linear)
            wr2 = if(!is.null(r2_all) && "wr2" %in% names(r2_all) && !is.na(r2_all["wr2"])) r2_all["wr2"] else 
                  if(!is.null(r2_all) && "wpr2" %in% names(r2_all) && !is.na(r2_all["wpr2"])) r2_all["wpr2"] else NA
            r2_str = ifelse(is.na(pr2), "NA", sprintf("%.3f", pr2))
            wr2_str = ifelse(is.na(wr2), "NA", sprintf("%.3f", wr2))
        } else {
            # For glm.nb models, use data dimensions
            n_obs = nobs(m)
            n_repos = if("project" %in% names(d)) length(unique(d$project)) else NA
            n_devs = if("author" %in% names(d)) length(unique(d$author)) else NA
            fe = "None"
            r2_str = sprintf("%.3f", 1 - m$deviance/m$null.deviance)
            wr2_str = "NA"
        }
        
        stats_rows[[paste0("Coef_", i)]] = c("", as.character(n_obs), 
                                              ifelse(is.na(n_repos), "NA", as.character(n_repos)),
                                              ifelse(is.na(n_devs), "NA", as.character(n_devs)), 
                                              fe, r2_str, wr2_str)
        stats_rows[[paste0("SE_", i)]] = c("", "", "", "", "", "", "")
    }
    
    # Combine
    full_df = rbind(summary_df, stats_rows)
    
    # Create nice column headers
    n_models = if(include_baseline) 1 + length(model_names) else length(model_names)
    header_names = c("Language")
    if (include_baseline) header_names = c(header_names, "M1: Ray et al. 2014", "")
    for (i in seq_along(model_names)) {
        header_names = c(header_names, model_names[i], "")
    }
    names(full_df) = header_names
    
    # Generate HTML table
    kable(full_df, format = "html", escape = FALSE, align = c("l", rep(c("r", "r"), n_models))) %>%
        kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE, font_size = 12) %>%
        row_spec(nrow(summary_df), extra_css = "border-bottom: 2px solid #333;") %>%
        footnote(general = "Significance (FDR-adjusted): * p<0.05, ** p<0.01, *** p<0.001. Standard errors in parentheses.")
}

# Generate summary table
createSummaryTable(
    results_list = list(result_repo, result_repo_fe, result_dev_fe, result_twoway_fe),
    model_names = c("M2: Berger et al. 2019", "M3: Repo-Lang\n(NBR+Repo FE)", 
                    "M4: Dev-Lang\n(Pois+Dev FE)", "M5: Dev-Repo-Lang\n(Pois+2way FE)"),
    models_list = list(nbr_repo, nbr_repo_fe, nbr_dev_fe, pois_dev_repo_twoway_fe),
    data_list = list(panel_repo, panel_repo, panel_dev, panel_dev_repo)
)
```